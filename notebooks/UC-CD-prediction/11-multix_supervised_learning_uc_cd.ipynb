{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature importance - supervised learning evaluation, transcriptomics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook sets up the basis for a supervised learning-driven approach to evaluate feature importance, leveraging the multiple omics types available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import sparc_multiomics.constants as const\n",
        "from sparc_multiomics.machine_learning import train_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the transcriptomics, genomics, proteomics and metadata. Merge it, keep only colon samples and UC/CD samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transcriptomics_data = pd.read_parquet(\"transcriptomics_batch_corrected.parquet\")\n",
        "transcriptomics_data = transcriptomics_data.drop(columns=[\"original_batch\"]).add_prefix(\n",
        "    \"transcriptomics:\"\n",
        ")\n",
        "transcriptomics_columns = transcriptomics_data.drop(\n",
        "    columns=[\"transcriptomics:sample_id\"]\n",
        ").columns\n",
        "genomics = pd.read_parquet(\"genomics_annotated.parquet\").add_prefix(\"genomics:\")\n",
        "genomics_columns = genomics.drop(columns=[\"genomics:sample_id\"]).columns\n",
        "proteomics = pd.read_parquet(\"proteomics_processed.parquet\").add_prefix(\"proteomics:\")\n",
        "proteomics_columns = proteomics.drop(columns=[\"proteomics:sample_id\"]).columns\n",
        "metadata = pd.read_parquet(\"collapsed_metadata.parquet\")\n",
        "metadata = metadata[\n",
        "    (metadata[\"diagnosis\"] != \"ibd_unclassified\")\n",
        "    & (metadata[\"transcriptomics\"].notna())\n",
        "    & (metadata[\"genomics_array\"].notna())\n",
        "    & (metadata[\"proteomics\"].notna())\n",
        "    & (metadata[\"simple_tissue\"] == \"colon\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_transcriptomics = pd.merge(\n",
        "    metadata,\n",
        "    transcriptomics_data,\n",
        "    left_on=\"transcriptomics\",\n",
        "    right_on=\"transcriptomics:sample_id\",\n",
        "    how=\"left\",\n",
        ")\n",
        "merged_transcriptomics_proteomics = pd.merge(\n",
        "    merged_transcriptomics,\n",
        "    proteomics,\n",
        "    left_on=\"proteomics\",\n",
        "    right_on=\"proteomics:sample_id\",\n",
        "    how=\"left\",\n",
        ")\n",
        "merged_transcriptomics_proteomics_genomics = pd.merge(\n",
        "    merged_transcriptomics_proteomics,\n",
        "    genomics,\n",
        "    left_on=\"genomics_array\",\n",
        "    right_on=\"genomics:sample_id\",\n",
        "    how=\"left\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Processing data subsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By iteratively splitting the data according to the available disease scores, it is then saved into the dictionary as mentioned above. Furthermore, columns with low variance (**<5%**) are excluded, and ANOVA is deployed against the target variable to identify most usable features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dictionary = {}\n",
        "features_columns = (\n",
        "    list(transcriptomics_columns) + list(proteomics_columns) + list(genomics_columns)\n",
        ")\n",
        "current_table = merged_transcriptomics_proteomics_genomics[\n",
        "    merged_transcriptomics_proteomics_genomics[\"diagnosis\"].notna()\n",
        "]\n",
        "\n",
        "print(\n",
        "    f\"\\n=====diagnosis:{current_table['diagnosis'].value_counts()}=====\\n\",\n",
        ")\n",
        "# barplot with class distribution\n",
        "\n",
        "sns.countplot(x=\"diagnosis\", data=current_table)\n",
        "plt.show()\n",
        "\n",
        "features_table = current_table[features_columns]\n",
        "\n",
        "mapping_dictionary = {\"uc\": 0, \"cd\": 1}\n",
        "labels_vector = current_table[\"diagnosis\"].map(mapping_dictionary)\n",
        "\n",
        "data_dictionary[\"diagnosis\"] = {\n",
        "    \"features\": features_table.reset_index(drop=True),\n",
        "    \"labels\": labels_vector.reset_index(drop=True),\n",
        "    \"mapping\": mapping_dictionary,\n",
        "    \"ids\": current_table[[\"patient_id\", \"interval_id\"]].reset_index(drop=True),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train an Extreme Gradient Boosting classifier on our data, performing nested k-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "methods_dictionary_classification = {\n",
        "    \"XGB\": [\n",
        "        XGBClassifier(random_state=const.RANDOM_SEED),\n",
        "        {\n",
        "            \"n_estimators\": [100, 250, 500],\n",
        "            \"max_depth\": [3, 5, 7],\n",
        "            \"eval_metric\": [\"logloss\", \"error\", \"auc\", \"aucpr\"],\n",
        "        },\n",
        "    ],\n",
        "}\n",
        "\n",
        "output_file_name = f\"results/feature_importance_diagnosis.csv\"\n",
        "unique_classes = len(data_dictionary[\"diagnosis\"][\"labels\"].unique())\n",
        "print(f\"$=$=$=$Processing diagnosis with XGB$=$=$=$\")\n",
        "print(\n",
        "    f\"Number of classes: {unique_classes}, which are: {', '.join([str(x) for x in data_dictionary['diagnosis']['mapping'].keys()])}\"\n",
        ")\n",
        "estimator, predictions, features_importances, scaler = train_model(\n",
        "    methods_dictionary_classification[\"XGB\"],\n",
        "    data_dictionary[\"diagnosis\"],\n",
        "    writing_tag=f\"classification_diagnosis\",\n",
        "    identifier_column_tag=\"patient_id\",\n",
        ")\n",
        "\n",
        "# Write estimator to disk\n",
        "with open(\"results/uc_cd_prediction_model.pkl\", \"wb\") as output_file:\n",
        "    pickle.dump(estimator, output_file)\n",
        "\n",
        "print(f\"Successfully generated:{output_file_name}\")\n",
        "\n",
        "importances_dataframe = pd.DataFrame(\n",
        "    features_importances,\n",
        "    index=list(data_dictionary[\"diagnosis\"][\"features\"].columns),\n",
        ")\n",
        "\n",
        "importances_dataframe.columns = [\"Importance\"]\n",
        "importances_dataframe[\"full_name\"] = importances_dataframe.index\n",
        "\n",
        "importances_dataframe[[\"omic\", \"Gene Name\"]] = importances_dataframe[\n",
        "    \"full_name\"\n",
        "].str.split(\":\", expand=True)\n",
        "\n",
        "transcriptomics_importances = (\n",
        "    importances_dataframe.loc[importances_dataframe[\"omic\"] == \"transcriptomics\"]\n",
        "    .sort_values(\"Importance\", ascending=False)\n",
        "    .iloc[0:10, :]\n",
        ")\n",
        "proteomics_importances = (\n",
        "    importances_dataframe.loc[importances_dataframe[\"omic\"] == \"proteomics\"]\n",
        "    .sort_values(\"Importance\", ascending=False)\n",
        "    .iloc[0:10, :]\n",
        ")\n",
        "genomics_importances = (\n",
        "    importances_dataframe.loc[importances_dataframe[\"omic\"] == \"genomics\"]\n",
        "    .sort_values(\"Importance\", ascending=False)\n",
        "    .iloc[0:10, :]\n",
        ")\n",
        "\n",
        "# Make three barplots, onr for each omic, in the same plot\n",
        "fig, ax = plt.subplots(1, 3, figsize=(10, 10))\n",
        "sns.barplot(\n",
        "    x=[x.replace(\"transcriptomics:\", \"\") for x in transcriptomics_importances.index],\n",
        "    y=transcriptomics_importances[\"Importance\"],\n",
        "    ax=ax[0],\n",
        "    palette=[\"#16EB96\" for x in transcriptomics_importances.index],\n",
        ")\n",
        "ax[0].set_title(\"Transcriptomics\")\n",
        "\n",
        "sns.barplot(\n",
        "    x=[\n",
        "        x.replace(\"proteomics:\", \"\").split(\"_\")[0] for x in proteomics_importances.index\n",
        "    ],\n",
        "    y=proteomics_importances[\"Importance\"],\n",
        "    ax=ax[1],\n",
        "    palette=[\"#F4B183\" for x in proteomics_importances.index],\n",
        ")\n",
        "ax[1].set_title(\"Proteomics\")\n",
        "sns.barplot(\n",
        "    x=[x.replace(\"genomics:\", \"\").split(\"_\")[0] for x in genomics_importances.index],\n",
        "    y=genomics_importances[\"Importance\"],\n",
        "    ax=ax[2],\n",
        "    palette=[\"#3B3838\" for x in proteomics_importances.index],\n",
        ")\n",
        "ax[2].set_title(\"Genomics\")\n",
        "\n",
        "for current_ax in ax:\n",
        "    current_ax.set_xticklabels(current_ax.get_xticklabels(), rotation=90)\n",
        "\n",
        "    current_ax.set_yticklabels(current_ax.get_yticklabels(), rotation=45, fontsize=6)\n",
        "plt.subplots_adjust(wspace=0.5)\n",
        "# Add a title to the plot\n",
        "plt.suptitle(f\"Feature importance for diagnosis using XGB\")\n",
        "plt.savefig(f\"results/feature_importance_diagnosis.png\")\n",
        "plt.show()\n",
        "plt.clf()\n",
        "importances_dataframe.sort_values(by=[\"Importance\"], ascending=False).to_csv(\n",
        "    \"results/features_importance.csv\", index=False\n",
        ")\n",
        "np.savetxt(\"results/uc_cd_predictions.csv\", predictions, delimiter=\",\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
