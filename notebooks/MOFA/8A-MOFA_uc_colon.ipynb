{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOFA for multi-omics data segmentation on UC and colon tissue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from mofapy2.run.entry_point import entry_point\n",
    "from sparc_multiomics.utils import (\n",
    "    prepare_table_MOFA,\n",
    "    prepare_covariates_MOFA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aiobotocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "proteomics = pd.read_parquet(\"proteomics_processed.parquet\")\n",
    "transcriptomics = pd.read_parquet(\"transcriptomics_batch_corrected.parquet\")\n",
    "genomics = pd.read_parquet(\"genomics_annotated.parquet\")\n",
    "metadata = pd.read_parquet(\"collapsed_metadata.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsetting the data to only include colon samples and uc patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_metadata = metadata[\n",
    "    (metadata[\"diagnosis\"] == \"uc\") & (metadata[\"simple_tissue\"] == \"colon\")\n",
    "]\n",
    "metadata_columns = subset_metadata.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of interest for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_columns = [\n",
    "    \"sex\",\n",
    "    \"diagnosis\",\n",
    "    \"endo_category\",\n",
    "    \"sub_location\",\n",
    "    \"characteristics_bio_material\",\n",
    "    \"macroscopic_appearance\",\n",
    "    \"mayo_6_score\",\n",
    "    \"scdai_score\",\n",
    "    \"mayo_9_score\",\n",
    "    \"disease_activity_60\",\n",
    "    \"perianal\",\n",
    "    \"abdominal_pain_score\",\n",
    "    \"global_assessment_score\",\n",
    "    \"rectal_bleeding_score\",\n",
    "    \"stool_freq_score\",\n",
    "    \"batch\",\n",
    "    \"simple_tissue\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_na_metadata = subset_metadata[\n",
    "    (subset_metadata[\"proteomics\"].notna())\n",
    "    & (subset_metadata[\"transcriptomics\"].notna())\n",
    "    & (subset_metadata[\"genomics_array\"].notna())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode metadata variables for further use as covariates and set the `patient_interval_id` as unique identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_metadata = []\n",
    "for current_clinical_feature in clinical_columns:\n",
    "    one_hot_encoded_metadata.append(\n",
    "        pd.get_dummies(\n",
    "            no_na_metadata[current_clinical_feature],\n",
    "            prefix=current_clinical_feature,\n",
    "        )\n",
    "    )\n",
    "one_hot_encoded_metadata = pd.concat(one_hot_encoded_metadata, axis=1)\n",
    "one_hot_encoded_metadata_columns = list(one_hot_encoded_metadata.columns)\n",
    "encoded_metadata = pd.concat([no_na_metadata, one_hot_encoded_metadata], axis=1)\n",
    "\n",
    "encoded_metadata[\"patient_id\"] = \"P\" + encoded_metadata[\"patient_id\"].astype(str)\n",
    "encoded_metadata[\"patient_interval_id\"] = (\n",
    "    encoded_metadata[\"patient_id\"].astype(str)\n",
    "    + \"_\"\n",
    "    + encoded_metadata[\"interval_id\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the transcriptomics features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3304, 19442) (3304, 19443)\n"
     ]
    }
   ],
   "source": [
    "transcriptomics_features = transcriptomics.drop(columns=[\"sample_id\", \"original_batch\"])\n",
    "transcriptomics_columns = list(transcriptomics_features.columns)\n",
    "scaler = StandardScaler()\n",
    "transcriptomics_features = pd.DataFrame(\n",
    "    scaler.fit_transform(transcriptomics_features),\n",
    "    transcriptomics_features.index,\n",
    "    columns=transcriptomics_features.columns,\n",
    ")\n",
    "transcriptomics_features[\"sample_id\"] = transcriptomics[\"sample_id\"]\n",
    "print(transcriptomics_features.shape, transcriptomics.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the proteomics features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2250, 2940) (2250, 2940)\n"
     ]
    }
   ],
   "source": [
    "proteomics_features = proteomics.drop(columns=[\"sample_id\"])\n",
    "scaler = StandardScaler()\n",
    "proteomics_features = pd.DataFrame(\n",
    "    scaler.fit_transform(proteomics_features),\n",
    "    proteomics_features.index,\n",
    "    columns=proteomics_features.columns,\n",
    ")\n",
    "proteomics_columns = list(proteomics_features.columns)\n",
    "proteomics_features[\"sample_id\"] = proteomics[\"sample_id\"]\n",
    "print(proteomics_features.shape, proteomics.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the genomics features, only for feeding MOFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomics_features = genomics.drop(columns=[\"sample_id\"])\n",
    "scaler = StandardScaler()\n",
    "genomics_features = pd.DataFrame(\n",
    "    scaler.fit_transform(genomics_features),\n",
    "    genomics_features.index,\n",
    "    columns=genomics_features.columns,\n",
    ")\n",
    "\n",
    "genomics_features = genomics_features.loc[:, genomics_features.var() > 0.00]\n",
    "genomics_columns = list(genomics_features.columns)\n",
    "genomics_features[\"sample_id\"] = genomics[\"sample_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain the merge of all omics types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_transcriptomics = encoded_metadata.merge(\n",
    "    transcriptomics_features,\n",
    "    left_on=\"transcriptomics\",\n",
    "    right_on=\"sample_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "merged_transcriptomics_proteomics = (\n",
    "    merged_transcriptomics.drop(columns=[\"sample_id\"])\n",
    "    .merge(proteomics_features, left_on=\"proteomics\", right_on=\"sample_id\", how=\"left\")\n",
    "    .drop(columns=[\"sample_id\"])\n",
    ")\n",
    "\n",
    "merged_transcriptomics_proteomics_genomics = merged_transcriptomics_proteomics.merge(\n",
    "    genomics_features, left_on=\"genomics_array\", right_on=\"sample_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "merged_transcriptomics_proteomics_genomics = (\n",
    "    merged_transcriptomics_proteomics_genomics.loc[\n",
    "        merged_transcriptomics_proteomics_genomics[\"macroscopic_appearance\"].isin(\n",
    "            [\"normal\", \"inflamed\"]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the data for MOFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptomics_block = prepare_table_MOFA(\n",
    "    merged_transcriptomics_proteomics_genomics,\n",
    "    sample_id_column_name=\"patient_interval_id\",\n",
    "    view_column_name=\"transcriptomics\",\n",
    "    group_column_name=\"macroscopic_appearance\",\n",
    "    features_columns_names=transcriptomics_columns,\n",
    ")\n",
    "proteomics_block = prepare_table_MOFA(\n",
    "    merged_transcriptomics_proteomics_genomics,\n",
    "    sample_id_column_name=\"patient_interval_id\",\n",
    "    view_column_name=\"proteomics\",\n",
    "    group_column_name=\"macroscopic_appearance\",\n",
    "    features_columns_names=proteomics_columns,\n",
    ")\n",
    "genomics_block = prepare_table_MOFA(\n",
    "    merged_transcriptomics_proteomics_genomics,\n",
    "    sample_id_column_name=\"patient_interval_id\",\n",
    "    view_column_name=\"genomics\",\n",
    "    group_column_name=\"macroscopic_appearance\",\n",
    "    features_columns_names=genomics_columns,\n",
    ")\n",
    "covariates = prepare_covariates_MOFA(\n",
    "    merged_transcriptomics_proteomics_genomics,\n",
    "    sample_id_column_name=\"patient_interval_id\",\n",
    "    group_column_name=\"macroscopic_appearance\",\n",
    "    covariates_columns_names=[\n",
    "        \"sex_female\",\n",
    "        \"sex_male\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MOFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        #########################################################\n",
      "        ###           __  __  ____  ______                    ### \n",
      "        ###          |  \\/  |/ __ \\|  ____/\\    _             ### \n",
      "        ###          | \\  / | |  | | |__ /  \\ _| |_           ### \n",
      "        ###          | |\\/| | |  | |  __/ /\\ \\_   _|          ###\n",
      "        ###          | |  | | |__| | | / ____ \\|_|            ###\n",
      "        ###          |_|  |_|\\____/|_|/_/    \\_\\              ###\n",
      "        ###                                                   ### \n",
      "        ######################################################### \n",
      "       \n",
      " \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# initialise the entry point\n",
    "ent = entry_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling views to unit variance...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scale_views: if views have different ranges/variances, it is good practice to scale each view to unit variance. Default is False\n",
    "ent.set_data_options(scale_views=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_data = pd.concat(\n",
    "    [\n",
    "        transcriptomics_block,\n",
    "        proteomics_block,\n",
    "        genomics_block,\n",
    "    ],\n",
    "    axis=0,\n",
    ").sort_values(by=[\"view\", \"group\", \"sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loaded group='inflamed' view='genomics' with N=46 samples and D=166896 features...\n",
      "Loaded group='inflamed' view='proteomics' with N=46 samples and D=2939 features...\n",
      "Loaded group='inflamed' view='transcriptomics' with N=46 samples and D=19441 features...\n",
      "Loaded group='normal' view='genomics' with N=130 samples and D=166896 features...\n",
      "Loaded group='normal' view='proteomics' with N=130 samples and D=2939 features...\n",
      "Loaded group='normal' view='transcriptomics' with N=130 samples and D=19441 features...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ent.set_data_df(\n",
    "    ready_data,\n",
    "    likelihoods=[\"gaussian\", \"gaussian\", \"gaussian\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: 'ard_factors' in model_options should be set to True if using multiple groups unless you are using MEFISTO\n",
      "\n",
      "Model options:\n",
      "- Automatic Relevance Determination prior on the factors: False\n",
      "- Automatic Relevance Determination prior on the weights: True\n",
      "- Spike-and-slab prior on the factors: False\n",
      "- Spike-and-slab prior on the weights: True\n",
      "Likelihoods:\n",
      "- View 0 (genomics): gaussian\n",
      "- View 1 (proteomics): gaussian\n",
      "- View 2 (transcriptomics): gaussian\n",
      "\n",
      "\n",
      "\n",
      "weight_views set to True. Weighting the ELBO (the objective function) based on the number of features per view\n",
      "\n",
      "Loaded 2 covariate(s) for each sample...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ent.set_model_options(\n",
    "    factors=25,  # In the example 10 are used, in the paper 25, doesn't matter much, as it will go automatically go down anyway\n",
    "    spikeslab_weights=True,\n",
    "    ard_weights=True,\n",
    "    ard_factors=False,\n",
    ")\n",
    "ent.set_train_options(\n",
    "    convergence_mode=\"fast\",\n",
    "    dropR2=0.02,  # When this is commented, factors are not dropped; changed to 2% because that was referred on the paper\n",
    "    gpu_mode=False,\n",
    "    seed=42,\n",
    "    weight_views=True,\n",
    ")\n",
    "ent.set_covariates(\n",
    "    covariates,\n",
    "    covariates_names=[\n",
    "        \"sex_female\",\n",
    "        \"sex_male\",\n",
    "    ],\n",
    ")\n",
    "ent.set_smooth_options(\n",
    "    scale_cov=False, model_groups=False\n",
    ")  # Model groups is set to False because we are not using it, the Default True usually leads to an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "######################################\n",
      "## Training the model with seed 42 ##\n",
      "######################################\n",
      "\n",
      "\n",
      "ELBO before training: -63750969.73 \n",
      "\n",
      "Iteration 1: time=9.44, ELBO=-6112203.44, deltaELBO=57638766.291 (90.41237575%), Factors=24\n",
      "Iteration 2: time=8.98, ELBO=-5496251.98, deltaELBO=615951.452 (0.96618366%), Factors=23\n",
      "Iteration 3: time=8.44, ELBO=-5237566.93, deltaELBO=258685.049 (0.40577430%), Factors=22\n",
      "Iteration 4: time=8.28, ELBO=-5118076.33, deltaELBO=119490.605 (0.18743339%), Factors=21\n",
      "Iteration 5: time=7.76, ELBO=-5041806.41, deltaELBO=76269.917 (0.11963727%), Factors=20\n",
      "Iteration 6: time=7.44, ELBO=-4995609.84, deltaELBO=46196.575 (0.07246411%), Factors=19\n",
      "Iteration 7: time=7.00, ELBO=-4962076.35, deltaELBO=33533.491 (0.05260075%), Factors=18\n",
      "Iteration 8: time=6.78, ELBO=-4941093.44, deltaELBO=20982.908 (0.03291386%), Factors=17\n",
      "Iteration 9: time=6.52, ELBO=-4919781.70, deltaELBO=21311.743 (0.03342968%), Factors=16\n",
      "Iteration 10: time=5.95, ELBO=-4911521.81, deltaELBO=8259.885 (0.01295649%), Factors=15\n",
      "Iteration 11: time=5.64, ELBO=-4906916.52, deltaELBO=4605.289 (0.00722387%), Factors=14\n",
      "Iteration 12: time=5.25, ELBO=-4907845.33, deltaELBO=-928.804 (0.00145693%), Factors=13\n",
      "Warning, lower bound is decreasing...\u0007\n",
      "Iteration 13: time=4.94, ELBO=-4909220.35, deltaELBO=-1375.028 (0.00215687%), Factors=12\n",
      "Warning, lower bound is decreasing...\u0007\n",
      "Iteration 14: time=4.73, ELBO=-4898320.08, deltaELBO=10900.278 (0.01709822%), Factors=12\n",
      "Iteration 15: time=4.64, ELBO=-4890707.99, deltaELBO=7612.088 (0.01194035%), Factors=12\n",
      "Iteration 16: time=4.73, ELBO=-4884752.83, deltaELBO=5955.155 (0.00934128%), Factors=12\n",
      "Iteration 17: time=4.67, ELBO=-4879830.08, deltaELBO=4922.748 (0.00772184%), Factors=12\n",
      "Iteration 18: time=4.67, ELBO=-4875633.81, deltaELBO=4196.271 (0.00658229%), Factors=12\n",
      "Iteration 19: time=4.64, ELBO=-4871986.64, deltaELBO=3647.170 (0.00572096%), Factors=12\n",
      "Optimising sigma node...\n",
      "Iteration 20: time=6.60, ELBO=-4868649.06, deltaELBO=3337.587 (0.00523535%), Factors=12\n",
      "Iteration 21: time=4.63, ELBO=-4865839.19, deltaELBO=2809.860 (0.00440756%), Factors=12\n",
      "Iteration 22: time=4.73, ELBO=-4863374.92, deltaELBO=2464.278 (0.00386548%), Factors=12\n",
      "Iteration 23: time=4.94, ELBO=-4861231.71, deltaELBO=2143.204 (0.00336184%), Factors=12\n",
      "Iteration 24: time=4.92, ELBO=-4859403.44, deltaELBO=1828.273 (0.00286784%), Factors=12\n",
      "Iteration 25: time=4.66, ELBO=-4857872.13, deltaELBO=1531.305 (0.00240201%), Factors=12\n",
      "Iteration 26: time=4.77, ELBO=-4856593.87, deltaELBO=1278.266 (0.00200509%), Factors=12\n",
      "Iteration 27: time=4.68, ELBO=-4855492.50, deltaELBO=1101.364 (0.00172760%), Factors=12\n",
      "Iteration 28: time=4.72, ELBO=-4854510.30, deltaELBO=982.204 (0.00154069%), Factors=12\n",
      "Iteration 29: time=4.69, ELBO=-4853610.03, deltaELBO=900.269 (0.00141217%), Factors=12\n",
      "Optimising sigma node...\n",
      "Iteration 30: time=6.92, ELBO=-4852764.09, deltaELBO=845.945 (0.00132695%), Factors=12\n",
      "Iteration 31: time=4.67, ELBO=-4851954.67, deltaELBO=809.418 (0.00126966%), Factors=12\n",
      "Iteration 32: time=4.73, ELBO=-4851166.43, deltaELBO=788.244 (0.00123644%), Factors=12\n",
      "Iteration 33: time=4.67, ELBO=-4850386.84, deltaELBO=779.587 (0.00122286%), Factors=12\n",
      "Iteration 34: time=4.72, ELBO=-4849603.96, deltaELBO=782.876 (0.00122802%), Factors=12\n",
      "Iteration 35: time=4.66, ELBO=-4848807.49, deltaELBO=796.472 (0.00124935%), Factors=12\n",
      "Iteration 36: time=4.64, ELBO=-4847988.26, deltaELBO=819.231 (0.00128505%), Factors=12\n",
      "Iteration 37: time=4.61, ELBO=-4847138.67, deltaELBO=849.585 (0.00133266%), Factors=12\n",
      "Iteration 38: time=4.63, ELBO=-4846253.28, deltaELBO=885.389 (0.00138882%), Factors=12\n",
      "Iteration 39: time=4.62, ELBO=-4845329.29, deltaELBO=923.991 (0.00144938%), Factors=12\n",
      "Optimising sigma node...\n",
      "Iteration 40: time=6.72, ELBO=-4844366.62, deltaELBO=962.675 (0.00151006%), Factors=12\n",
      "Iteration 41: time=4.60, ELBO=-4843370.85, deltaELBO=995.771 (0.00156197%), Factors=12\n",
      "Iteration 42: time=4.63, ELBO=-4842355.46, deltaELBO=1015.387 (0.00159274%), Factors=12\n",
      "Iteration 43: time=4.62, ELBO=-4841340.02, deltaELBO=1015.441 (0.00159282%), Factors=12\n",
      "Iteration 44: time=4.61, ELBO=-4840343.12, deltaELBO=996.895 (0.00156373%), Factors=12\n",
      "Iteration 45: time=4.58, ELBO=-4839375.80, deltaELBO=967.323 (0.00151735%), Factors=12\n",
      "Iteration 46: time=4.63, ELBO=-4838440.11, deltaELBO=935.695 (0.00146773%), Factors=12\n",
      "Iteration 47: time=4.59, ELBO=-4837530.68, deltaELBO=909.430 (0.00142654%), Factors=12\n",
      "Iteration 48: time=4.63, ELBO=-4836637.66, deltaELBO=893.018 (0.00140079%), Factors=12\n",
      "Iteration 49: time=4.58, ELBO=-4835749.20, deltaELBO=888.463 (0.00139365%), Factors=12\n",
      "Optimising sigma node...\n",
      "Iteration 50: time=6.84, ELBO=-4742915.56, deltaELBO=92833.640 (0.14561918%), Factors=12\n",
      "Iteration 51: time=4.59, ELBO=-4737376.90, deltaELBO=5538.660 (0.00868796%), Factors=12\n",
      "Iteration 52: time=4.65, ELBO=-4734669.90, deltaELBO=2706.996 (0.00424620%), Factors=12\n",
      "Iteration 53: time=4.59, ELBO=-4733124.14, deltaELBO=1545.761 (0.00242469%), Factors=12\n",
      "Iteration 54: time=4.61, ELBO=-4732135.33, deltaELBO=988.810 (0.00155105%), Factors=12\n",
      "Iteration 55: time=4.58, ELBO=-4731426.58, deltaELBO=708.752 (0.00111175%), Factors=12\n",
      "Iteration 56: time=4.61, ELBO=-4730867.16, deltaELBO=559.422 (0.00087751%), Factors=12\n",
      "Iteration 57: time=4.65, ELBO=-4730392.34, deltaELBO=474.815 (0.00074480%), Factors=12\n",
      "Iteration 58: time=4.65, ELBO=-4729968.45, deltaELBO=423.888 (0.00066491%), Factors=12\n",
      "Iteration 59: time=4.57, ELBO=-4729577.38, deltaELBO=391.075 (0.00061344%), Factors=12\n",
      "Optimising sigma node...\n",
      "Iteration 60: time=6.80, ELBO=-4729209.03, deltaELBO=368.351 (0.00057780%), Factors=12\n",
      "Iteration 61: time=4.60, ELBO=-4728857.56, deltaELBO=351.463 (0.00055131%), Factors=12\n",
      "Iteration 62: time=4.65, ELBO=-4728519.07, deltaELBO=338.493 (0.00053096%), Factors=12\n",
      "Iteration 63: time=4.60, ELBO=-4728190.88, deltaELBO=328.194 (0.00051481%), Factors=12\n",
      "Iteration 64: time=4.67, ELBO=-4727870.78, deltaELBO=320.093 (0.00050210%), Factors=12\n",
      "Iteration 65: time=4.59, ELBO=-4727557.12, deltaELBO=313.662 (0.00049201%), Factors=12\n",
      "Iteration 66: time=4.68, ELBO=-4727248.75, deltaELBO=308.375 (0.00048372%), Factors=12\n",
      "\n",
      "Converged!\n",
      "\n",
      "\n",
      "\n",
      "#######################\n",
      "## Training finished ##\n",
      "#######################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model in mofa_inflammation_uc_colon.h5...\n",
      "upload: ./mofa_inflammation_cd_colon.h5 to s3://enveda-data-dx/mofa/mofa_inflammation_uc_colon.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the output\n",
    "ent.save(outfile=\"mofa_inflammation_uc_colon.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
