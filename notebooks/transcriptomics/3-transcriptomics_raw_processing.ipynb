{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing and addressing transcriptomics batch effect in CCF data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the purpose of segmenting multi-omics data from the Chron's & Colitis Foundation (CCF), we deploy Non-negative Matrix Factorization (NMF) upon the transcriptomics data, as we did before, to replicate the batch effect identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import copy\n",
    "from pydeseq2 import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is merely a reformatting and documented version of Daniel Ence's original processing in his [original notebook](https://github.com/enveda/dx-transcriptomics/blob/main/notebooks/scratch.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wr.s3.read_csv(\n",
    "    \"transcriptomics_raw_data.txt.gz\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"path\", \"symbol\", \"gene_id\", \"count\"],\n",
    "    compression=\"gzip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>symbol</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sparc-cd-genewiz/hit-counts/hit-counts/FS01628...</td>\n",
       "      <td>DDX11L1, transcribed_unprocessed_pseudogene, H...</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sparc-cd-genewiz/hit-counts/hit-counts/FS01628...</td>\n",
       "      <td>WASH7P, unprocessed_pseudogene, HGNC:38034</td>\n",
       "      <td>ENSG00000227232</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sparc-cd-genewiz/hit-counts/hit-counts/FS01628...</td>\n",
       "      <td>MIR6859-1, miRNA, HGNC:50039</td>\n",
       "      <td>ENSG00000278267</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sparc-cd-genewiz/hit-counts/hit-counts/FS01628...</td>\n",
       "      <td>MIR1302-2HG, lncRNA, HGNC:52482</td>\n",
       "      <td>ENSG00000243485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sparc-cd-genewiz/hit-counts/hit-counts/FS01628...</td>\n",
       "      <td>FAM138A, lncRNA, HGNC:32334</td>\n",
       "      <td>ENSG00000237613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  sparc-cd-genewiz/hit-counts/hit-counts/FS01628...   \n",
       "1  sparc-cd-genewiz/hit-counts/hit-counts/FS01628...   \n",
       "2  sparc-cd-genewiz/hit-counts/hit-counts/FS01628...   \n",
       "3  sparc-cd-genewiz/hit-counts/hit-counts/FS01628...   \n",
       "4  sparc-cd-genewiz/hit-counts/hit-counts/FS01628...   \n",
       "\n",
       "                                              symbol          gene_id  count  \n",
       "0  DDX11L1, transcribed_unprocessed_pseudogene, H...  ENSG00000223972      0  \n",
       "1         WASH7P, unprocessed_pseudogene, HGNC:38034  ENSG00000227232     69  \n",
       "2                       MIR6859-1, miRNA, HGNC:50039  ENSG00000278267     21  \n",
       "3                    MIR1302-2HG, lncRNA, HGNC:52482  ENSG00000243485      0  \n",
       "4                        FAM138A, lncRNA, HGNC:32334  ENSG00000237613      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing column naming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpacking the path column into `batch`, `filename` and `sample_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the batch column from the first part of path\n",
    "data[\"batch\"] = data[\"path\"].str.split(\"/\").str[0]\n",
    "\n",
    "# Generate the filename columm from the fourth part of path\n",
    "data[\"filename\"] = data[\"path\"].str.split(\"/\").str[3]\n",
    "\n",
    "# Get the sample_id from the filename, as the part before the first dot\n",
    "data[\"sample_id\"] = data[\"filename\"].str.split(\".\").str[0]\n",
    "\n",
    "# Get the symbol parts, as an intermediate step to get the symbol, feature_type, and HGNC_id\n",
    "data[\"symbol_parts\"] = data[\"symbol\"].str.split(\",\")\n",
    "\n",
    "# Get the symbol, feature_type, and HGNC_id from the symbol_parts\n",
    "data[\"symbol\"] = data[\"symbol_parts\"].str[0]\n",
    "data[\"feature_type\"] = data[\"symbol_parts\"].str[1].str.strip()\n",
    "data[\"HGNC_id\"] = data[\"symbol_parts\"].str[2].str.strip()\n",
    "\n",
    "# Drop the symbol_parts, HGNC_id, feature_type, path, and filename columns, as they are no longer needed\n",
    "data.drop(\n",
    "    columns=[\"symbol_parts\", \"HGNC_id\", \"feature_type\", \"path\", \"filename\"],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Convert the count column to int\n",
    "data[\"sample_id\"] = data[\"sample_id\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Midpoint copy because some of the steps might have issues and need to be rerun because of memory\n",
    "mid_processed = copy.deepcopy(data)\n",
    "\n",
    "# Concatenate the symbol and gene_id to get the gene_name\n",
    "mid_processed[\"gene_name\"] = mid_processed[\"symbol\"] + \"_\" + mid_processed[\"gene_id\"]\n",
    "\n",
    "# Generate a new column for the expanded sample_id\n",
    "mid_processed[\"expand_sample\"] = (\n",
    "    mid_processed[\"sample_id\"] + \"_\" + mid_processed[\"batch\"]\n",
    ")\n",
    "\n",
    "# Drop the symbol, gene_id, smaple_od, and batch columns, as they are no longer needed\n",
    "mid_processed = mid_processed.drop(columns=[\"symbol\", \"gene_id\", \"sample_id\", \"batch\"])\n",
    "\n",
    "# Unnamed genes values appear as duplicated, so lets drop them as we have no way to distinguish\n",
    "mid_processed = mid_processed.dropna(subset=[\"gene_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing and dropping low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot the table and isolate `sample_id` and `batch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the mid_processed dataframe to get the genes by samples dataframe\n",
    "genes_by_samples_df = mid_processed.pivot(\n",
    "    index=\"gene_name\", columns=\"expand_sample\", values=\"count\"\n",
    ")\n",
    "\n",
    "# Transpose the genes_by_samples_df to get the samples by genes dataframe\n",
    "genes_by_samples_df = genes_by_samples_df.T\n",
    "\n",
    "genes_by_samples_df[\"sample_id\"] = genes_by_samples_df.index.str.split(\"_\").str[0]\n",
    "genes_by_samples_df[\"batch\"] = genes_by_samples_df.index.str.split(\"_\").str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform normalization with `pydeseq2` on each of the batches, multiply by the size factors, then concatenate the table back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the unique batches\n",
    "unique_batches = genes_by_samples_df[\"batch\"].unique()\n",
    "processed_batches = []\n",
    "for batch in unique_batches:\n",
    "    batch_df = genes_by_samples_df[genes_by_samples_df[\"batch\"] == batch]\n",
    "\n",
    "    # Isoalte the sample_id and batch columns\n",
    "    batch_ids = batch_df[[\"sample_id\", \"batch\"]]\n",
    "\n",
    "    # Isolate the counts columns\n",
    "    batch_counts = batch_df.drop(columns=[\"sample_id\", \"batch\"])\n",
    "\n",
    "    # Normalize the counts using pydeseq2\n",
    "    pydeseq2_results_counts, pydeseq2_results_size_factors = preprocessing.deseq2_norm(\n",
    "        batch_counts.values\n",
    "    )\n",
    "\n",
    "    # Convert the pydeseq2_results_counts to a dataframe\n",
    "    pydeseq2_dataframe = pd.DataFrame(\n",
    "        pydeseq2_results_counts,\n",
    "        columns=batch_counts.columns,\n",
    "        index=batch_counts.index,\n",
    "    )\n",
    "\n",
    "    # Multiply pydeseq2_dataframe columns by pydeseq2_results_size_factors\n",
    "    final_pydeseq2_dataframe = pydeseq2_dataframe.mul(\n",
    "        pydeseq2_results_size_factors, axis=0\n",
    "    )\n",
    "    final_pydeseq2_dataframe[[\"sample_id\", \"batch\"]] = batch_ids\n",
    "    processed_batches.append(final_pydeseq2_dataframe)\n",
    "\n",
    "# Concatenate the processed batches batch together\n",
    "processed_batches_df = pd.concat(processed_batches, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column with 0 variance\n",
    "\n",
    "processed_batches_ids = processed_batches_df[[\"sample_id\", \"batch\"]]\n",
    "\n",
    "final_processed_df = processed_batches_df.drop(columns=[\"sample_id\", \"batch\"]).loc[\n",
    "    :, processed_batches_df.drop(columns=[\"sample_id\", \"batch\"]).var() != 0\n",
    "]\n",
    "final_processed_df[[\"sample_id\", \"batch\"]] = processed_batches_ids\n",
    "\n",
    "final_processed_df = final_processed_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the columns with gene name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the columns with gene names\n",
    "only_named_columns = []\n",
    "for x in final_processed_df.columns:\n",
    "    split_column = x.split(\"_\")\n",
    "    if split_column[0] != \"\":\n",
    "        only_named_columns.append(x)\n",
    "\n",
    "final_processed_df = final_processed_df[only_named_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the output table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_processed_df.to_parquet(\"transcriptomics_pydeseq_corrected.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
